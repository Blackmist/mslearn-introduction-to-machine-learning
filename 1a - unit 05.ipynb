{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48f468d4",
   "metadata": {},
   "source": [
    "# Exercise: Train a multiple linear regression model\n",
    "In this exercise, we will train both a simple linear regression model and a multiple linear regresion model, and compare their performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf34a5c",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "Let's begin by having a look at our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4be5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as graph\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from numpy import polyfit, poly1d, reshape, array, meshgrid\n",
    "import joblib\n",
    "\n",
    "#Import the data from the .csv file\n",
    "dataset = pd.read_csv('auto-mpg-cleaned.csv')\n",
    "\n",
    "#Let's have a look at the data\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abfcf55",
   "metadata": {},
   "source": [
    "The y values, or labels, are represented by the mpg column. These are the values we are training our model to predict. There are 8 features for each label, which means that each y value is defined as a function of these 8 x values. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2778ad0c",
   "metadata": {},
   "source": [
    "## Data visualization\n",
    "Let's have a look at how the labels are distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa39df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "xval = dataset['mpg']\n",
    "\n",
    "# Create a figure for 2 subplots (2 rows, 1 column)\n",
    "fig, ax = graph.subplots(2, 1)\n",
    "\n",
    "# Plot the histogram   \n",
    "ax[0].hist(xval, bins='auto')\n",
    "ax[0].set_ylabel('cars')\n",
    "\n",
    "# Add lines for the mean and median\n",
    "ax[0].axvline(xval.mean(), color='green', linestyle='dashed', linewidth=2)\n",
    "ax[0].axvline(xval.median(), color='red', linestyle='dashed', linewidth=2)\n",
    "\n",
    "# Plot the boxplot   \n",
    "ax[1].boxplot(xval, vert=False)\n",
    "ax[1].set_xlabel('mpg')\n",
    "ax[1].set_ylabel('cars')\n",
    "\n",
    "# Add a title to the Figure\n",
    "fig.suptitle('mpg distribution')\n",
    "\n",
    "graph.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e9a706",
   "metadata": {},
   "source": [
    "The locations of the cars' median and mean mpg values tell us that the majority of them have lower mpg. \n",
    "Indeed, the only outlier (denoted by a cirle on the boxplot) is a car with an mpg value of over 45."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ce21ef",
   "metadata": {},
   "source": [
    "We can visualize the numerical features of our dataset in a similar manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef2bc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = dataset.iloc[:,2:7]\n",
    "print(numerical_features)\n",
    "for feature in numerical_features:\n",
    "\n",
    "    %matplotlib inline\n",
    "\n",
    "    xval = numerical_features[feature]\n",
    "\n",
    "    # Create a figure for 2 subplots (2 rows, 1 column)\n",
    "    fig, ax = graph.subplots(2, 1)\n",
    "\n",
    "    # Plot the histogram   \n",
    "    ax[0].hist(xval, bins='auto')\n",
    "    ax[0].set_ylabel('Cars')\n",
    "\n",
    "    # Add lines for the mean and median\n",
    "    ax[0].axvline(xval.mean(), color='orange', linestyle='dashed', linewidth=2)\n",
    "    ax[0].axvline(xval.median(), color='red', linestyle='dashed', linewidth=2)\n",
    "\n",
    "    # Plot the boxplot   \n",
    "    ax[1].boxplot(xval, vert=False)\n",
    "    ax[1].set_xlabel(feature)\n",
    "    ax[1].set_ylabel('Cars')\n",
    "\n",
    "    # Add a title to the Figure\n",
    "    fig.suptitle(str(feature)+' distribution')\n",
    "\n",
    "    graph.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa491f8d",
   "metadata": {},
   "source": [
    "It can also be useful to plot the cars' mpg as a function of each feature, to gain an understanding of how they relate to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67eb5c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in numerical_features:\n",
    "    xval = numerical_features[feature]\n",
    "    yval = dataset['mpg']\n",
    "    %matplotlib inline\n",
    "    graph.scatter(xval, yval,  color='steelblue')\n",
    "    graph.ylabel('mpg')\n",
    "    graph.xlabel(feature)\n",
    "    graph.title('mpg as a function of ' + feature)\n",
    "    graph.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3637aed6",
   "metadata": {},
   "source": [
    "We can see that there is either a positive or negative correlation between a car's mpg and each of these numerical features. This makes sense, as we expect newer cars to have a higher mpg, and heavier cars to have a lower mpg for example!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ca4e31",
   "metadata": {},
   "source": [
    "Now, what about the categorical features? Well, with a few changes to our code, we can visualise them too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477b826d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's use pandas' concatenate function to create our categorical features subset\n",
    "categorical_features = pd.concat([dataset.iloc[:,1],dataset.iloc[:,7:]],axis=1)\n",
    "\n",
    "\n",
    "#Let's transform the vehicle names into unique integer identifiers for ease of use\n",
    "\n",
    "unique_car_name = categorical_features['car name'].unique()\n",
    "car_ids = dict(zip(unique_car_name, range(len(unique_car_name))))\n",
    "categorical_features['car name'] = categorical_features['car name'].map(car_ids)\n",
    "\n",
    "print(categorical_features)\n",
    "\n",
    "for feature in categorical_features:\n",
    "    \n",
    "    %matplotlib inline\n",
    "    xval = categorical_features[feature]    \n",
    "    counts = xval.value_counts().sort_index()\n",
    "    fig = graph.figure()\n",
    "    ax = graph.gca()\n",
    "    counts.plot.bar(ax = ax, color='steelblue')\n",
    "    ax.set_title(feature + ' counts')\n",
    "    ax.set_xlabel(feature) \n",
    "    ax.set_ylabel(\"Frequency\")\n",
    "\n",
    "    graph.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef29dbf5",
   "metadata": {},
   "source": [
    "This tells us that most cars come from a single country, and that the vast majority of cars have got 4-cylinder engines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63a63c3",
   "metadata": {},
   "source": [
    "## Simple linear regression\n",
    "We've had a look at the data, so now let's create a model that can predict cars' mpg performance. Let's first explore the effect of a single feature, the car's weight, on its mpg performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6585ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = array(dataset['weight'])\n",
    "y = array(dataset['mpg'])\n",
    "\n",
    "#random_state for reproducibilty\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=0)\n",
    "\n",
    "#reshape arrays for 'LinearRegression'\n",
    "\n",
    "X_train = X_train.reshape(-1,1)\n",
    "y_train = y_train.reshape(-1,1)\n",
    "X_test = X_test.reshape(-1,1)\n",
    "y_test = y_test.reshape(-1,1)\n",
    "\n",
    "model = LinearRegression().fit(X_train,y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Show a graph of the result\n",
    "# Don't worry about how this is done for now\n",
    "%matplotlib inline\n",
    "intercept = model.intercept_\n",
    "slope = model.coef_\n",
    "line = slope * X_test + intercept\n",
    "graph.scatter(X_test, y_test,  color='steelblue')\n",
    "graph.plot(X_test, line, '-', c = 'orange')\n",
    "graph.ylabel('mpg')\n",
    "graph.xlabel('weight')\n",
    "graph.show()\n",
    "\n",
    "rms = mean_squared_error(y_test,y_pred, squared=False)\n",
    "print(f\"RMSE: {rms}\")\n",
    "\n",
    "#Let's save this model in case we want to use it later\n",
    "#Save the model as a pickle file\n",
    "filename = './cars_mpg_weight_model.pkl'\n",
    "joblib.dump(model, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f110b6",
   "metadata": {},
   "source": [
    "## Multiple linear regression\n",
    "There seems to be a relationship between a car's weight and its mpg performance. Let's see what happens if we include an extra feature into the mix, like its engine displacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5dcb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = array(dataset[['weight','displacement']])\n",
    "y = array(dataset['mpg'])\n",
    "\n",
    "#random_state for reproducibilty\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=0)\n",
    "\n",
    "#reshape arrays for 'LinearRegression'\n",
    "\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_test = y_test.reshape(-1,1)\n",
    "\n",
    "model = LinearRegression().fit(X_train,y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Show a graph of the result\n",
    "# Don't worry about how this is done for now\n",
    "%matplotlib inline\n",
    "fig = graph.figure()\n",
    "ax = Axes3D(fig)\n",
    "\n",
    "x_plot = X_test[:,0].flatten()\n",
    "y_plot = X_test[:,1].flatten()\n",
    "z_plot = y_test.flatten()\n",
    "\n",
    "x_grid,y_grid = meshgrid(x_plot,y_plot)\n",
    "z_grid = y_pred\n",
    "\n",
    "ax.set_xlabel('weight')\n",
    "ax.set_ylabel('displacement')\n",
    "ax.set_zlabel('mpg')\n",
    "\n",
    "ax.scatter(x_plot,y_plot,z_plot, color='steelblue')\n",
    "ax.plot_surface(x_grid,y_grid,z_grid, cmap=cm.cool, alpha=0.01)\n",
    "\n",
    "rms = mean_squared_error(y_test,y_pred, squared=False)\n",
    "print(f\"RMSE: {rms}\")\n",
    "\n",
    "#Let's save this model in case we want to use it later\n",
    "# Save the model as a pickle file\n",
    "filename = './cars_mpg_weight_displacement_model.pkl'\n",
    "joblib.dump(model, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d919ea44",
   "metadata": {},
   "source": [
    "The RMSE of this multiple linear regression model is lower than that of the simple linear regression mod. Using multiple features allows to make more accurate predictions when testing a model on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf6c34d",
   "metadata": {},
   "source": [
    "## Summary\n",
    "We covered the following concepts in this exercise:\n",
    "\n",
    "- Quickly visualize a dataset's labels, numerical, and categorical features.\n",
    "- Build Single and Multiple Linear Regression Models.\n",
    "- Compare the performance of both models visually, and as a function of RMSE."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
