{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd05fd7d2d989b956829c9ad45cc6f2d78f0054d35d23dba8942e8fbd9b2870e6f3",
   "display_name": "Python 3.8.5 64-bit ('venv')"
  },
  "metadata": {
   "interpreter": {
    "hash": "5fd7d2d989b956829c9ad45cc6f2d78f0054d35d23dba8942e8fbd9b2870e6f3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Exercise: Feature Scaling\n",
    "\n",
    "Definition and exercise content.\n",
    "\n",
    "notes and refs:\n",
    "\n",
    "https://www.baeldung.com/cs/normalization-vs-standardization\n",
    "\n",
    "https://scikit-learn.org/stable/modules/preprocessing.html#standardization-or-mean-removal-and-variance-scaling\n",
    "\n",
    "https://stats.stackexchange.com/questions/324369/feature-scaling-giving-reduced-output-linear-regression-using-gradient-descent\n",
    "\n",
    "\n",
    "Surprisingly, feature scaling doesn’t improve the regression performance in our case. Actually, following the same steps on well-known toy datasets won’t increase the model’s success.\n",
    "\n",
    "However, this doesn’t mean feature scaling is unnecessary for linear regression. Even the sci-kit implementation has a boolean normalize parameter to automatically normalize the input when set to True.\n",
    "\n",
    "Instead, this result reminds us that there’s no fit for all preprocessing methods in machine learning. We need to carefully examine the dataset and apply customized methods.\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "min_max_scaler = MinMaxScaler().fit(X_test)\n",
    "X_norm = min_max_scaler.transform(X)\n",
    "\n",
    "As a rule of thumb, we fit a scaler on the test data, then transform the whole dataset with it. By doing this, we completely ignore the test dataset while building the model.\n",
    "\n",
    "Normalizing the concrete dataset, we get:\n",
    "\n",
    "## Preparing data\n",
    "......\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   shoe_size_eu  height     sex  age_years  shoe_size_usa\n",
       "0            39     173    male         60              6\n",
       "1            38     173    male         48              5\n",
       "2            37     157  female         43              4\n",
       "3            39     175    male         51              6\n",
       "4            38     170    male         39              5"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>shoe_size_eu</th>\n      <th>height</th>\n      <th>sex</th>\n      <th>age_years</th>\n      <th>shoe_size_usa</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>39</td>\n      <td>173</td>\n      <td>male</td>\n      <td>60</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>38</td>\n      <td>173</td>\n      <td>male</td>\n      <td>48</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>37</td>\n      <td>157</td>\n      <td>female</td>\n      <td>43</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>39</td>\n      <td>175</td>\n      <td>male</td>\n      <td>51</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>38</td>\n      <td>170</td>\n      <td>male</td>\n      <td>39</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# Import everything we will need for this unit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import operator\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "\n",
    "# Load data from our dataset file into a pandas dataframe\n",
    "# dataset = pd.read_csv('Data/investments.csv', index_col=False, sep=\",\",header=0)\n",
    "\n",
    "# # Check what's in the dataset\n",
    "# print(dataset.head())\n",
    "\n",
    "\n",
    "\n",
    "# Load a file containing people's shoe sizes\n",
    "# and height, both in cm\n",
    "data = pd.read_csv('Data/shoe-size-height.csv')\n",
    "\n",
    "# Convert EU shoe sizes to the USA shoe sizes\n",
    "# that we sell in our store\n",
    "data[\"shoe_size_usa\"] = data.shoe_size_eu - 33\n",
    "\n",
    "# Print the first few rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "RMSE metrics: 5.8944593557470295\nR2 metrics: 0.5807836498967944\n"
     ]
    }
   ],
   "source": [
    "model = smf.ols(formula = \"height ~ shoe_size_usa\", data = data).fit()\n",
    "\n",
    "X = data[\"shoe_size_usa\"].to_numpy()\n",
    "y = data[\"height\"].to_numpy()\n",
    "y_hat = model.predict(data[\"shoe_size_usa\"])\n",
    "\n",
    "# Calculate metrics\n",
    "rmse_1 = np.sqrt(mean_squared_error(y,y_hat))\n",
    "r2_1 = r2_score(y,y_hat)\n",
    "\n",
    "print(f\"RMSE metrics (without scaling): {rmse_1}\")\n",
    "print(f\"R2 metrics(without scaling): {r2_1}\")\n"
   ]
  },
  {
   "source": [
    "Explain dataset, \n",
    "\n",
    "why features need scaling\n",
    "\n",
    "train unscaled model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "RMSE metrics: 5.894459355747031\nR2 metrics: 0.5807836498967942\n"
     ]
    }
   ],
   "source": [
    "# Now scale stuff\n",
    "\n",
    "scaler = StandardScaler()\n",
    "data[\"shoe_size_usa\"] = scaler.fit_transform(data[\"shoe_size_usa\"].to_numpy().reshape(-1, 1))\n",
    "model2 = smf.ols(formula = \"height ~ shoe_size_usa\", data = data).fit()\n",
    "y_hat2 = model2.predict(data[\"shoe_size_usa\"])\n",
    "\n",
    "# Calculate metrics\n",
    "rmse_2 = np.sqrt(mean_squared_error(y,y_hat2))\n",
    "r2_2 = r2_score(y,y_hat2)\n",
    "\n",
    "print(f\"RMSE metrics (with feature scaling): {rmse_2}\")\n",
    "print(f\"R2 metrics(with feature scaling): {r2_2}\")\n"
   ]
  },
  {
   "source": [
    "Show how to scale features, train new  model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a model comparison\n",
    "\n",
    "\n",
    "# # Use a dataframe to create a comparison table of metrics\n",
    "# l = [[\"Original Model\", original_rmse, original_r2],\n",
    "#     [\"Custom Model\", rmse, r2]]\n",
    "\n",
    "# pd.DataFrame(l, columns=[\"\", \"RMSE\", \"R2\"])"
   ]
  },
  {
   "source": [
    "Conclusion"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "\n",
    "\n",
    "## Summary\n",
    "\n",
    ".....\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}