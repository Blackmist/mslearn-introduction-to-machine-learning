{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3710jvsc74a57bd0a970c7e51787c6ef7f3c805442fbb5a30ae2745635e1d2514e62d936ba85c55c",
   "display_name": "Python 3.7.10 64-bit ('ml_crash_course': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "5fd7d2d989b956829c9ad45cc6f2d78f0054d35d23dba8942e8fbd9b2870e6f3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Exercise: Titanic Dataset - Types of Data and Handling Missing Data\n",
    "\n",
    "To build better Machine Learning models we have to understand that there's different types of data used to describe both **features** and **labels**:\n",
    "\n",
    "- Real Valued data: Numerical data that is often continuous, such as \"Age\", \"Salary\" or \"Number of Relatives\".\n",
    "\n",
    "- Categorical data: Describes data that have labels with no particular no order, such as \"Sex\" (Male, Female) or \"Blood Type\" (A, B, AB, O). They can be represented by numbers or text, but must be converted into a numerical format for processing.\n",
    "\n",
    "- Identity data: Data that is used to uniquely identify a record, such as an \"ID\", \"SSN\" or \"Name\".\n",
    "\n",
    "As we've seen, incomplete data can negatively affect a model's perfomance or even completely stop it from working, hence why it's important to identify and correct gaps in our datasets.\n",
    "\n",
    "In this exercise we take a deeper look into the Titanic Dataset, then build and compare Machine Learning models with the original and \"cleaned\" data.\n",
    "\n",
    "## Preparing data\n",
    "\n",
    "Let's reload the Titanic Dataset and reacquaint ourselves with its data:\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data from our dataset file into a pandas dataframe\n",
    "dataset = pd.read_csv('Data/titanic.csv', index_col=False, sep=\",\",header=0)\n",
    "\n",
    "# Let's take a look at the data\n",
    "dataset.head()\n"
   ]
  },
  {
   "source": [
    "Taking a careful look at the columns and data we can identify the **Real Valued** features, like `Age`, `SibSp`, `Parch` and `Fare` and **Categorical** features, such as `Survived`, `Sex`, `PClass` and `Embarked`. \n",
    "\n",
    "\n",
    "We can display a brief summary of the dataypes by using panda's `info()` method:\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 891 entries, 0 to 890\nData columns (total 12 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   PassengerId  891 non-null    int64  \n 1   Survived     891 non-null    int64  \n 2   Pclass       891 non-null    int64  \n 3   Name         891 non-null    object \n 4   Sex          891 non-null    object \n 5   Age          714 non-null    float64\n 6   SibSp        891 non-null    int64  \n 7   Parch        891 non-null    int64  \n 8   Ticket       891 non-null    object \n 9   Fare         891 non-null    float64\n 10  Cabin        204 non-null    object \n 11  Embarked     889 non-null    object \ndtypes: float64(2), int64(5), object(5)\nmemory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "source": [
    "We can see that several columns are stored as numerical data (those with `int64` or `float64` types), while others contain more complex data types (those with `object` as Dtype)\n",
    "\n",
    "Notice that `dataset.info()` also shows us the number of non-null items per column, but does not indicate if a feature is Categorical or Real valued.\n",
    "\n",
    "## Handling Missing Data\n",
    "\n",
    "As seen in the last Unit, the Titanic Dataset is not 100% complete:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "             Empty Cells\nPassengerId            0\nSurvived               0\nPclass                 0\nName                   0\nSex                    0\nAge                  177\nSibSp                  0\nParch                  0\nTicket                 0\nFare                   0\nCabin                687\nEmbarked               2\n"
     ]
    }
   ],
   "source": [
    "# Calculate the number of empty cells in each column\n",
    "# and store it in a new dataframe\n",
    "missing_data = dataset.isnull().sum().to_frame()\n",
    "\n",
    "# Rename column holding the sums\n",
    "missing_data = missing_data.rename(columns={0:'Empty Cells'})\n",
    "\n",
    "# Print the results\n",
    "print(missing_data)"
   ]
  },
  {
   "source": [
    "\n",
    "\n",
    "Some rows in the `Age`, `Cabin` and `Embarked` have \"empty\" cells (or cells where the value is `null`). \n",
    "\n",
    "There are **many** ways to address this issue, each with pros and cons.\n",
    "\n",
    "Let's take a look at the less complicated options:\n",
    "\n",
    "### Option 1: Delete data with missing rows\n",
    "\n",
    "When we have a model that cannot handle missing data, the most prudent thing to do is to remove rows that have information missing.\n",
    "\n",
    "Let's remove some data from the `Embarked` column, which only two rows with missing data."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The original size of our dataset was (891, 12)\nThe shape for the clean dataset is (889, 12)\n"
     ]
    }
   ],
   "source": [
    "# Create a \"clean\" dataset where we cumulatively fix missing values\n",
    "# Start by removing rows ONLY where \"Embarked\" has no values\n",
    "print(f\"The original size of our dataset was\", dataset.shape)\n",
    "clean_dataset = dataset.drop(dataset[dataset[\"Embarked\"].isnull()].index)\n",
    "clean_dataset = clean_dataset.reindex()\n",
    "\n",
    "# How many rows do we have now?\n",
    "print(\"The shape for the clean dataset is\", clean_dataset.shape)\n"
   ]
  },
  {
   "source": [
    "We can see that the offending two rows are not present in our new clean dataset.\n",
    "\n",
    "### Option 2: Replace empty values with the mean or median for that data.\n",
    "\n",
    "In some circumstances, our model cannot handle missing values, and we also cannot afford to remove too much data. If this is the case, sometimes we can fill missing data with the average of the rest of the dataset. \n",
    "\n",
    "Below, we do this for the `Age` field, and since it holds **Real valued** data and we can make a reasonable estimation of the mean Age from the remaining rows, given that >80% of these are not empty:\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The mean age is 29.64209269662921\n             Empty Cells\nPassengerId            0\nSurvived               0\nPclass                 0\nName                   0\nSex                    0\nAge                    0\nSibSp                  0\nParch                  0\nTicket                 0\nFare                   0\nCabin                687\nEmbarked               0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Calculate the mean value for the Age column\n",
    "mean_age = clean_dataset[\"Age\"].mean()\n",
    "\n",
    "print(\"The mean age is\", mean_age)\n",
    "\n",
    "# Replace empty values in \"Age\" with the mean calculated above\n",
    "clean_dataset[\"Age\"].fillna(mean_age, inplace=True)\n",
    "\n",
    "# Let's see what the clean dataset looks like now\n",
    "print(clean_dataset.isnull().sum().to_frame().rename(columns={0:'Empty Cells'}))"
   ]
  },
  {
   "source": [
    "As you can see above, the `Age` field has no empty cells anymore.\n",
    "\n",
    "### Option 3: Assign a new category to unknown categorical data\n",
    "\n",
    "The `Cabin` field is a categorical field because there's a finite number of possible options for cabins in the Titanic. Unfortunately, many records have no cabin listed.\n",
    "\n",
    "For this exercise it makes perfect sense to create an `Unknown` category and assign it to the cases where the cabin is unknown:\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "             Empty Cells\nPassengerId            0\nSurvived               0\nPclass                 0\nName                   0\nSex                    0\nAge                    0\nSibSp                  0\nParch                  0\nTicket                 0\nFare                   0\nCabin                  0\nEmbarked               0\n"
     ]
    }
   ],
   "source": [
    "# Assign unknow to records where \"Cabin\" is empty\n",
    "clean_dataset[\"Cabin\"].fillna(\"Unknown\", inplace=True)\n",
    "\n",
    "# Let's see what the clean dataset looks like now\n",
    "print(clean_dataset.isnull().sum().to_frame().rename(columns={0:'Empty Cells'}))\n",
    "\n",
    "# Save the clean dataset for future use\n",
    "clean_dataset.to_csv(\"Data/Cleaned_Titanic.csv\")"
   ]
  },
  {
   "source": [
    "That's it! No more missing data!\n",
    "\n",
    "We only lost two records (where `Embarked` was empty). \n",
    "\n",
    "That said, we had to make some approximations to fill the missing gaps for the `Age` and `Cabin` columns, and those will certainly influence the performance of any model we train on this data. In many instances, it is better to simply remove data that are missing, or to use a model that is designed to handle missing values. Exactly which is best will depend on your circumstances.\n",
    "\n",
    "## Model performance with cleaned Data\n",
    "\n",
    "Let's take a quick look at how cleaning data can improve a model's performance, by building a models with either the cleaned data or the original data. \n",
    "\n",
    "The models we will build predict whether a person would survive or perish in the sinking of the Titanic.\n",
    "\n",
    "We can use an algorithm called \"Logistic Regression\" to make this kind of prediction with the dataset we have:\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cleaned data. Score: 0.7096296296296296, Loss: 0.6734830137281654\nOriginal data. Score: 0.6982248520710059, Loss: 0.6805265405413654\n"
     ]
    }
   ],
   "source": [
    "import sklearn.model_selection as model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "# We will try to predict survival based on the following features (Columns)\n",
    "features = [\"Age\", \"SibSp\", \"Parch\", \"Fare\"]\n",
    "\n",
    "\n",
    "# First, make dataset we will test both models on. This should be \n",
    "# data that, before cleaning, did not lack any of the features\n",
    "# -- Find passengers where all features are not null\n",
    "eligible_rows = (~dataset[features].isnull()).sum(axis=1) == len(features)\n",
    "passengers_with_full_information = dataset[eligible_rows].PassengerId\n",
    "\n",
    "# -- Randomly select some passenger Ids\n",
    "_, test_passenger_ids = model_selection.train_test_split(passengers_with_full_information, test_size=0.30, random_state=101)\n",
    "\n",
    "# -- Extract our feature columns for these passengers,\n",
    "# -- giving us our test dataset\n",
    "test_rows = dataset[dataset.PassengerId.isin(test_passenger_ids)]\n",
    "X_test = test_rows[features]\n",
    "y_test = test_rows.Survived\n",
    "\n",
    "# Now create a function we can use to train and test a model\n",
    "def train_logistic_regression(data):\n",
    "    '''\n",
    "    Trains a model to predict survival on the Titanic\n",
    "    This is tested against a test dataset that had no data missing \n",
    "    '''\n",
    "\n",
    "    # Extract training data from the dataset\n",
    "    # This is all passengers who are not in the test set\n",
    "    data = data[~data.PassengerId.isin(test_passenger_ids)]\n",
    "\n",
    "    # X is our feature matrix\n",
    "    X = data[features]\n",
    "\n",
    "    # y is the label vector \n",
    "    y = data.Survived\n",
    "\n",
    "    # train the model\n",
    "    model = LogisticRegression(random_state=0).fit(X, y)\n",
    "\n",
    "    # score is the mean accuracy on the given test data and labels\n",
    "    score = model.score(X, y)\n",
    "\n",
    "    # calculate loss\n",
    "    probabilities = model.predict_proba(X_test)\n",
    "    loss = metrics.log_loss(y_test, probabilities)\n",
    "\n",
    "    return score, loss\n",
    "\n",
    "\n",
    "# Train a model with the clean data\n",
    "clean_score, clean_loss = train_logistic_regression(clean_dataset)\n",
    "print(f\"Cleaned data. Score: {clean_score}, Loss: {clean_loss}\")\n",
    "\n",
    "\n",
    "# Train a model with the original (not cleaned) data\n",
    "# Note that the model will not run if there are values missing,\n",
    "# so for the sake of this exercise, we will replace missing values \n",
    "# with 0s\n",
    "original_data = dataset.copy(deep=True)\n",
    "original_data[\"Age\"].fillna(0, inplace=True)\n",
    "original_score, original_loss = train_logistic_regression(original_data)\n",
    "\n",
    "print(f\"Original data. Score: {original_score}, Loss: {original_loss}\")"
   ]
  },
  {
   "source": [
    "The **clean** model yields both a better score and a smaller loss, as expected.\n",
    "\n",
    "## Summary\n",
    "\n",
    "In this Unit you've learned about different types of data and the importance of dealing with missing values before training our model.\n",
    "\n",
    "Recall that we discussed the options of deleting rows with missing data, replacing `null` values in a numeric column with the `mean` of its valid values, and creating new categories for unknown categorical data, but that there are more sophisticated ways to make these corrections. \n",
    "\n",
    "Finally, we built and compared models built with the original dataset and a \"cleaned\" dataset, with the latter model showing the best results.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}