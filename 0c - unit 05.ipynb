{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "pythonjvsc74a57bd05fd7d2d989b956829c9ad45cc6f2d78f0054d35d23dba8942e8fbd9b2870e6f3",
   "display_name": "Python 3.8.5  ('venv': venv)"
  },
  "metadata": {
   "interpreter": {
    "hash": "5fd7d2d989b956829c9ad45cc6f2d78f0054d35d23dba8942e8fbd9b2870e6f3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Exercise: Titanic Dataset - Types of Data and Handling Missing Data\n",
    "\n",
    "To build better Machine Learning models we have to understand that there's different types of data used to describe both **features** and **labels**:\n",
    "\n",
    "- Real Valued data: A number that describes a **quantitative** feature, such as \"Age\", \"Salary\" or \"Number of Relatives\".\n",
    "\n",
    "- Categorical data: Describes a **qualitative property**, such as \"Sex\", \"Occupation\" or \"Blood Type\". They can be represented by numbers or text, but must be converted into a numerical format for processing.\n",
    "\n",
    "- Identity data: Data that is used to uniquely identify a record, such as an \"ID\", \"SSN\" or \"Name\".\n",
    "\n",
    "Incomplete data can also negatively affect a model's perfomance and even completely stop it from working, hence why it's important to identify and correct gaps in our datasets.\n",
    "\n",
    "In this exercise we take a deeper look into the Titanic Dataset, then build and compare Machine Learning models with the original and \"cleaned\" data.\n",
    "\n",
    "## Preparing data\n",
    "\n",
    "Let's reload the Titanic Dataset and reacquaint ourselves with its data:\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data from our dataset file into a pandas dataframe\n",
    "dataset = pd.read_csv('Data/titanic.csv', index_col=False, sep=\",\",header=0)\n",
    "\n",
    "# Let's take a look at the data\n",
    "dataset.head()\n"
   ]
  },
  {
   "source": [
    "Taking a careful look at the columns and data we can identify the **Real Valued** features, like \"Age\", \"SibSp\", \"Parch\" and \"Fare\" and **Categorical** features, such as \"Survived\", \"Sex\", \"PClass\" and \"Embarked\". \n",
    "\n",
    "\n",
    "We can display a brief summary of the dataypes by using panda's `info()` method:\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 891 entries, 0 to 890\nData columns (total 12 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   PassengerId  891 non-null    int64  \n 1   Survived     891 non-null    int64  \n 2   Pclass       891 non-null    int64  \n 3   Name         891 non-null    object \n 4   Sex          891 non-null    object \n 5   Age          714 non-null    float64\n 6   SibSp        891 non-null    int64  \n 7   Parch        891 non-null    int64  \n 8   Ticket       891 non-null    object \n 9   Fare         891 non-null    float64\n 10  Cabin        204 non-null    object \n 11  Embarked     889 non-null    object \ndtypes: float64(2), int64(5), object(5)\nmemory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "source": [
    "Notice that `dataset.info()` also shows us the number of non-null items per column, but does not indicate if a feature is Categorical or Real valued."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "\n",
    "\n",
    "## Handling Missing Data\n",
    "\n",
    "As seen in the last Unit, the Titanic Dataset is not 100% complete:\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "             Empty Cells\nPassengerId            0\nSurvived               0\nPclass                 0\nName                   0\nSex                    0\nAge                  177\nSibSp                  0\nParch                  0\nTicket                 0\nFare                   0\nCabin                687\nEmbarked               2\n"
     ]
    }
   ],
   "source": [
    "# Calculate the number of empty cells in each column\n",
    "# and store it in a new dataframe\n",
    "missing_data = dataset.isnull().sum().to_frame()\n",
    "\n",
    "# Rename column holding the sums\n",
    "missing_data = missing_data.rename(columns={0:'Empty Cells'})\n",
    "\n",
    "# Print the results\n",
    "print(missing_data)"
   ]
  },
  {
   "source": [
    "\n",
    "\n",
    "Some rows in the \"Age\", \"Cabin\" and \"Embarked\" have \"empty\" cells (or cells where the value is `null`). \n",
    "\n",
    "There are **many** ways to address this issue, each with pros and cons.\n",
    "\n",
    "Let's take a look at the less complicated options:\n",
    "\n",
    "### Option 1: Delete data with missing rows\n",
    "\n",
    "The \"Embarked\" column is the perfect candidate for this option, because it has only two rows with missing data. By deleting them we don't lose too much information (in contrast, we would lose almost the entire dataset if we applied this to the \"Cabin\" column)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The shape for the clean dataset is (889, 12)\n"
     ]
    }
   ],
   "source": [
    "# Create a \"clean\" dataset where we cumulatively fix missing values\n",
    "# Start by removing rows ONLY where \"Embarked\" has no values\n",
    "clean_dataset = dataset.drop(dataset[dataset[\"Embarked\"].isnull()].index)\n",
    "clean_dataset = clean_dataset.reindex()\n",
    "\n",
    "# WE started with 891 rows in the dataset and deleted 2.\n",
    "# How many rows do we have now?\n",
    "print(f\"The shape for the clean dataset is {clean_dataset.shape}\")\n"
   ]
  },
  {
   "source": [
    "We expected `cleaned_dataset` to have 889 rows since we deleted 2 from the original dataset.\n",
    "\n",
    "### Option 2: Replace empty values with the mean or median for that data.\n",
    "\n",
    "We should use this option for \"Age\" field, and since it holds **Real valued** data and less that 20% of the rows are empty, we should have enough data to make a decent estimation for the mean age:\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "             Empty Cells\nPassengerId            0\nSurvived               0\nPclass                 0\nName                   0\nSex                    0\nAge                    0\nSibSp                  0\nParch                  0\nTicket                 0\nFare                   0\nCabin                687\nEmbarked               0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Calculate the mean value for the Age column\n",
    "mean_age = clean_dataset[\"Age\"].mean()  # 29.6420...\n",
    "\n",
    "# Replace empty values in \"Age\" with the mean calculated above\n",
    "clean_dataset[\"Age\"].fillna(mean_age, inplace=True)\n",
    "\n",
    "# Let's see what the clean dataset looks like now\n",
    "print(clean_dataset.isnull().sum().to_frame().rename(columns={0:'Empty Cells'}))"
   ]
  },
  {
   "source": [
    "As you can see above, the \"Age\" field has no empty cells anymore.\n",
    "\n",
    "### Option 3: Assign a new category to unknown categorical data\n",
    "\n",
    "The \"Cabin\" field is a categorical field. There's a finite number of possible options for cabins in the Titanic. Unfortunately, we don't know which of these should be applied to a large percentage of our records.\n",
    "\n",
    "For this exercise it makes perfect sense to create an \"Unknown\" category and assign it to the cases where the cabin is, well, not known:\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "             Empty Cells\nPassengerId            0\nSurvived               0\nPclass                 0\nName                   0\nSex                    0\nAge                    0\nSibSp                  0\nParch                  0\nTicket                 0\nFare                   0\nCabin                  0\nEmbarked               0\n"
     ]
    }
   ],
   "source": [
    "# Assign unknow to records where \"Cabin\" is empty\n",
    "clean_dataset[\"Cabin\"].fillna(\"Unknown\", inplace=True)\n",
    "\n",
    "# Let's see what the clean dataset looks like now\n",
    "print(clean_dataset.isnull().sum().to_frame().rename(columns={0:'Empty Cells'}))\n",
    "\n",
    "# Save the clean dataset for future use\n",
    "clean_dataset.to_csv(\"Data/Cleaned_Titanic.csv\")\n",
    "\n"
   ]
  },
  {
   "source": [
    "That's it! No more missing data!\n",
    "\n",
    "We only lost two records (where \"Embarked\" was empty), and although we had to make some approximations to fill the missing gaps for the \"Age\" and \"Cabin\" columns, and those will certainly influence the performance of our model, the dataset is ready to be used.\n",
    "\n",
    "### A Note on Categorical Data\n",
    "\n",
    "Most Machine Learning algorithms require that categorical data is converted into numbers before it is processed.\n",
    "\n",
    "One way to accomplish that is by using a technique called \"one-hot\" encoding, that transforms category names into a numeric vector.\n",
    "\n",
    "We will explain how that works in the next Unit, but for the sake of siplicity we will only use numerical data when building the models below.\n",
    "\n",
    "## Building a Model with Cleaned Data\n",
    "\n",
    "The model we will build to predict whether a person would survive or perish in the sinking of the Titanic can have have only to possible outcomes: `0` if the person perished, '1' if the person survived.\n",
    "\n",
    "We can use an algorithm called \"Logistic Regression\" to make this kind of prediction with the dataset we have:\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.model_selection as model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "# Let's remove categorical data and only the features that we deem relevant for this model\n",
    "clean_dataset = clean_dataset.drop([\"PassengerId\",\"Name\",\"Sex\",\"Ticket\",\"Cabin\",\"Embarked\", \"Pclass\"], axis=1)\n",
    "\n",
    "# X is our feature matrix\n",
    "X = clean_dataset[[\"Age\", \"SibSp\", \"Parch\", \"Fare\"]]\n",
    "\n",
    "# y is the label vector \n",
    "y = clean_dataset[\"Survived\"]\n",
    "\n",
    "# Create Train and test sets with a 70/30 split\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, train_size=0.70,test_size=0.30, random_state=101)\n",
    "\n",
    "# train the model\n",
    "model = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "\n",
    "# score is the mean accuracy on the given test data and labels\n",
    "score = model.score(X_train, y_train)\n",
    "\n",
    "# calculate loss\n",
    "probabilities = model.predict_proba(X_test)\n",
    "loss = metrics.log_loss(y_test, probabilities)\n",
    "\n",
    "# save results for comparison\n",
    "clean_score = score\n",
    "clean_loss = loss\n"
   ]
  },
  {
   "source": [
    "\n",
    "\n",
    "## Building a Model with \"Unclean\" Data\n",
    "\n",
    "Let's repeat the process with the original dataset:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's remove categorical data and only the features that we deem relevant for this model\n",
    "dataset = dataset.drop([\"PassengerId\",\"Name\",\"Sex\",\"Ticket\",\"Cabin\",\"Embarked\", \"Pclass\"], axis=1)\n",
    "\n",
    "# Fill empty Age cells with 0 otherwise Logistic Regression will not run.\n",
    "dataset[\"Age\"].fillna(0, inplace=True)\n",
    "\n",
    "# X is our feature matrix\n",
    "X = dataset[[\"Age\", \"SibSp\", \"Parch\", \"Fare\"]]\n",
    "\n",
    "# y is the label vector \n",
    "y = dataset[\"Survived\"]\n",
    "\n",
    "# Create Train and test sets with a 70/30 split\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, train_size=0.70,test_size=0.30, random_state=101)\n",
    "\n",
    "# train the model\n",
    "model = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "\n",
    "# score is the mean accuracy on the given test data and labels\n",
    "score = model.score(X_train, y_train)\n",
    "\n",
    "# calculate loss\n",
    "probabilities = model.predict_proba(X_test)\n",
    "loss = metrics.log_loss(y_test, probabilities)\n",
    "\n",
    "# save results for comparison\n",
    "unclean_score = score\n",
    "unclean_loss = loss"
   ]
  },
  {
   "source": [
    "## Comparing Models\n",
    "\n",
    "We gathered `score` and `loss` metrics for each model and can use these metrics to make an informed comparison:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Dataset     Score      Loss\n",
       "0    Clean  0.696141  0.609630\n",
       "1  Unclean  0.686998  0.645384"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Dataset</th>\n      <th>Score</th>\n      <th>Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Clean</td>\n      <td>0.696141</td>\n      <td>0.609630</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Unclean</td>\n      <td>0.686998</td>\n      <td>0.645384</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "# Use a dataframe to create a comparison table of metrics\n",
    "l = [[\"Clean\", clean_score, clean_loss],\n",
    "    [\"Unclean\", unclean_score, unclean_loss]]\n",
    "\n",
    "pd.DataFrame(l, columns=[\"Dataset\", \"Score\", \"Loss\"])"
   ]
  },
  {
   "source": [
    "The **clean** model yields both a better score and a smaller loss, as expected.\n",
    "\n",
    "## Summary\n",
    "\n",
    "In this Unit you've learned about different types of data and the importance of dealing with missing values before training our model.\n",
    "\n",
    "Recall that we discussed the options of deleting rows with missing data, replacing `null` values in a numeric column with the `mean` of its valid values, and creating new categories for unknown categorical data, but that there are other more sofisticated ways to make these corrections. \n",
    "\n",
    "Finally, we built and compared models built with the original dataset and a \"cleaned\" dataset, with the latter model showing the best results.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}