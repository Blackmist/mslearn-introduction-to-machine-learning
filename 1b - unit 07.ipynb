{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd05fd7d2d989b956829c9ad45cc6f2d78f0054d35d23dba8942e8fbd9b2870e6f3",
   "display_name": "Python 3.8.5 64-bit ('venv')"
  },
  "metadata": {
   "interpreter": {
    "hash": "5fd7d2d989b956829c9ad45cc6f2d78f0054d35d23dba8942e8fbd9b2870e6f3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Exercise: Feature Scaling\n",
    "\n",
    "Definition and exercise content.\n",
    "\n",
    "REFS: https://www.baeldung.com/cs/normalization-vs-standardization\n",
    "\n",
    "https://scikit-learn.org/stable/modules/preprocessing.html#standardization-or-mean-removal-and-variance-scaling\n",
    "\n",
    "\n",
    "https://stats.stackexchange.com/questions/324369/feature-scaling-giving-reduced-output-linear-regression-using-gradient-descent\n",
    "\n",
    "\n",
    "## Preparing data\n",
    "......\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "    mpg  cylinders  displacement  horsepower  weight  acceleration  \\\n0  27.0          4          97.0          88    2130          14.5   \n1  26.0          4         121.0         113    2234          12.5   \n2  26.0          4          97.0          46    1835          20.5   \n3  25.0          4         110.0          87    2672          17.5   \n4  25.0          4         104.0          95    2375          17.5   \n\n   model year  origin                      car name  \n0          70       3                  datsun pl510  \n1          70       2                      bmw 2002  \n2          70       2  volkswagen 1131 deluxe sedan  \n3          70       2                   peugeot 504  \n4          70       2                      saab 99e  \n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 392 entries, 0 to 391\nData columns (total 9 columns):\n #   Column        Non-Null Count  Dtype  \n---  ------        --------------  -----  \n 0   mpg           392 non-null    float64\n 1   cylinders     392 non-null    int64  \n 2   displacement  392 non-null    float64\n 3   horsepower    392 non-null    int64  \n 4   weight        392 non-null    int64  \n 5   acceleration  392 non-null    float64\n 6   model year    392 non-null    int64  \n 7   origin        392 non-null    int64  \n 8   car name      392 non-null    object \ndtypes: float64(3), int64(5), object(1)\nmemory usage: 27.7+ KB\nNone\n"
     ]
    }
   ],
   "source": [
    "# Import everything we will need for this unit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import operator\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "import SimpleLinearRegression as slr\n",
    "\n",
    "# Load data from our dataset file into a pandas dataframe\n",
    "dataset = pd.read_csv('Data/auto-mpg-cleaned.csv')\n",
    "\n",
    "# # Check what's in the dataset\n",
    "print(dataset.head())\n",
    "print(dataset.info())\n",
    "\n"
   ]
  },
  {
   "source": [
    "Explain dataset, \n",
    "\n",
    "why features need scaling\n",
    "\n",
    "train unscaled model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "RMSE metrics: inf\n",
      "R2 metrics: -inf\n",
      "/home/user/desenv/MS-ML-Exercises/venv/lib/python3.8/site-packages/sklearn/metrics/_regression.py:338: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0,\n",
      "/home/user/desenv/MS-ML-Exercises/venv/lib/python3.8/site-packages/sklearn/metrics/_regression.py:691: RuntimeWarning: overflow encountered in square\n",
      "  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0,\n"
     ]
    }
   ],
   "source": [
    "# Select only numerical features for training and testing\n",
    "# Convert both X and y to numpy arrays for processing\n",
    "X = dataset[['horsepower', 'weight', 'acceleration']].to_numpy()\n",
    "y = dataset['mpg'].to_numpy()\n",
    "\n",
    "# Split test and Train sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=0)\n",
    "\n",
    "# print(\"X_train\")\n",
    "# print(X_train)\n",
    "\n",
    "# Train model with unscaled features\n",
    "# We have to set normalize and fit_transform to False\n",
    "# to disable automatic scaling\n",
    "# model = LinearRegression(normalize=False)\n",
    "model = slr.SimpleLinearRegression()\n",
    "weights, J_history = model.fit(X_train,y_train, 0.0001, 100)\n",
    "\n",
    "# Evaluate using test_set\n",
    "y_hat = model.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "rmse_0 = np.sqrt(mean_squared_error(y_test,y_hat))\n",
    "r2_0 = r2_score(y_test,y_hat)\n",
    "\n",
    "print(f\"RMSE metrics: {rmse_0}\")\n",
    "print(f\"R2 metrics: {r2_0}\")\n"
   ]
  },
  {
   "source": [
    "Show how to scale features, train new  model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# Do a model comparison\n",
    "scaler = StandardScaler()\n",
    "X_norm = scaler.fit_transform(X)\n",
    "\n",
    "# X_norm2 = np.concatenate([np.ones((X_norm.shape[0], 1)), X_norm], axis=1)\n",
    "\n",
    "print(X_norm)\n",
    "\n",
    "# Split test and Train sets\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_norm, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# print(\"X_train\")\n",
    "# print(X_train2)\n",
    "\n",
    "# Train model with unscaled features\n",
    "# model2 = LinearRegression(normalize=False)\n",
    "# model2.fit(X_train,y_train)\n",
    "model2 = slr.SimpleLinearRegression()\n",
    "_, J_history2 = model2.fit(X_train2,y_train2, 0.0000002, 10000)\n",
    "\n",
    "# Evaluate using test_set\n",
    "y_hat2 = model2.predict(X_test2)\n",
    "\n",
    "# Calculate metrics\n",
    "rmse_1 = np.sqrt(mean_squared_error(y_test,y_hat2))\n",
    "r2_1 = r2_score(y_test2,y_hat2)\n",
    "\n",
    "print(f\"RMSE metrics: {rmse_1}\")\n",
    "print(f\"R2 metrics: {r2_1}\")\n",
    "\n",
    "# # Use a dataframe to create a comparison table of metrics\n",
    "# l = [[\"Unscaled Features\", original_rmse, original_r2],\n",
    "#     [\"Custom Model\", rmse, r2]]\n",
    "\n",
    "# pd.DataFrame(l, columns=[\"\", \"RMSE\", \"R2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "axes = fig.add_subplot()\n",
    "axes.set_title('Cost x Iterations for Different Learning Rates')\n",
    "\n",
    "l0 = plt.plot(np.arange(len(J_history)), J_history, lw=2, color=\"red\")\n",
    "l1 = plt.plot(np.arange(len(J_history2)), J_history2, lw=2, color=\"blue\")\n",
    "\n",
    "# Add legend\n",
    "red_patch = mpatches.Patch(color=\"red\", label=\"High\")\n",
    "blue_patch = mpatches.Patch(color=\"blue\", label=\"Low\")\n",
    "plt.legend(title = \"Learning Rate\", handles=[red_patch, blue_patch])\n",
    "plt.xlabel(\"Number of iterations\")\n",
    "_ = plt.ylabel(\"Cost\")"
   ]
  },
  {
   "source": [
    "Conclusion"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "\n",
    "\n",
    "## Summary\n",
    "\n",
    ".....\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}