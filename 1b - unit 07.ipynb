{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd05fd7d2d989b956829c9ad45cc6f2d78f0054d35d23dba8942e8fbd9b2870e6f3",
   "display_name": "Python 3.8.5 64-bit ('venv')"
  },
  "metadata": {
   "interpreter": {
    "hash": "5fd7d2d989b956829c9ad45cc6f2d78f0054d35d23dba8942e8fbd9b2870e6f3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Exercise: Feature Scaling\n",
    "\n",
    "Definition and exercise content.\n",
    "\n",
    "REFS: https://www.baeldung.com/cs/normalization-vs-standardization\n",
    "\n",
    "https://scikit-learn.org/stable/modules/preprocessing.html#standardization-or-mean-removal-and-variance-scaling\n",
    "\n",
    "\n",
    "https://stats.stackexchange.com/questions/324369/feature-scaling-giving-reduced-output-linear-regression-using-gradient-descent\n",
    "\n",
    "\n",
    "## Preparing data\n",
    "......\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "    mpg  cylinders  displacement  horsepower  weight  acceleration  \\\n0  27.0          4          97.0          88    2130          14.5   \n1  26.0          4         121.0         113    2234          12.5   \n2  26.0          4          97.0          46    1835          20.5   \n3  25.0          4         110.0          87    2672          17.5   \n4  25.0          4         104.0          95    2375          17.5   \n\n   model year  origin                      car name  \n0          70       3                  datsun pl510  \n1          70       2                      bmw 2002  \n2          70       2  volkswagen 1131 deluxe sedan  \n3          70       2                   peugeot 504  \n4          70       2                      saab 99e  \n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 392 entries, 0 to 391\nData columns (total 9 columns):\n #   Column        Non-Null Count  Dtype  \n---  ------        --------------  -----  \n 0   mpg           392 non-null    float64\n 1   cylinders     392 non-null    int64  \n 2   displacement  392 non-null    float64\n 3   horsepower    392 non-null    int64  \n 4   weight        392 non-null    int64  \n 5   acceleration  392 non-null    float64\n 6   model year    392 non-null    int64  \n 7   origin        392 non-null    int64  \n 8   car name      392 non-null    object \ndtypes: float64(3), int64(5), object(1)\nmemory usage: 27.7+ KB\nNone\n"
     ]
    }
   ],
   "source": [
    "# Import everything we will need for this unit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import operator\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "import SimpleLinearRegression as slr\n",
    "\n",
    "# Load data from our dataset file into a pandas dataframe\n",
    "dataset = pd.read_csv('Data/auto-mpg-cleaned.csv')\n",
    "\n",
    "# # Check what's in the dataset\n",
    "print(dataset.head())\n",
    "print(dataset.info())\n",
    "\n"
   ]
  },
  {
   "source": [
    "Explain dataset, \n",
    "\n",
    "why features need scaling\n",
    "\n",
    "train unscaled model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "X in class\n",
      "[[1.000e+00 6.300e+01 2.051e+03 1.700e+01]\n",
      " [1.000e+00 9.700e+01 2.405e+03 1.490e+01]\n",
      " [1.000e+00 1.250e+02 3.605e+03 1.500e+01]\n",
      " ...\n",
      " [1.000e+00 1.450e+02 3.988e+03 1.300e+01]\n",
      " [1.000e+00 1.000e+02 3.329e+03 1.550e+01]\n",
      " [1.000e+00 1.500e+02 4.498e+03 1.450e+01]]\n",
      "/home/user/desenv/MS-ML-Exercises/SimpleLinearRegression.py:42: RuntimeWarning: invalid value encountered in subtract\n",
      "  weights = weights - (learning_rate / m) * np.dot(h_vec - y, X)\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-66eea1cf5335>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Calculate metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mrmse_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0mr2_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/desenv/MS-ML-Exercises/venv/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/desenv/MS-ML-Exercises/venv/lib/python3.8/site-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[0;36m0.825\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \"\"\"\n\u001b[0;32m--> 335\u001b[0;31m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0m\u001b[1;32m    336\u001b[0m         y_true, y_pred, multioutput)\n\u001b[1;32m    337\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/desenv/MS-ML-Exercises/venv/lib/python3.8/site-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/desenv/MS-ML-Exercises/venv/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/desenv/MS-ML-Exercises/venv/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 663\u001b[0;31m             _assert_all_finite(array,\n\u001b[0m\u001b[1;32m    664\u001b[0m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/desenv/MS-ML-Exercises/venv/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m    101\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m    102\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    104\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                     (type_err,\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "# Select only numerical features for training and testing\n",
    "# Convert both X and y to numpy arrays for processing\n",
    "X = dataset[['horsepower', 'weight', 'acceleration']].to_numpy()\n",
    "y = dataset['mpg'].to_numpy()\n",
    "\n",
    "# Split test and Train sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=0)\n",
    "\n",
    "\n",
    "\n",
    "# print(\"X_train\")\n",
    "# print(X_train)\n",
    "\n",
    "# Train model with unscaled features\n",
    "# We have to set normalize and fit_transform to False\n",
    "# to disable automatic scaling\n",
    "# model = LinearRegression(normalize=False)\n",
    "model = slr.SimpleLinearRegression()\n",
    "weights, J_history = model.fit(X_train,y_train, 0.001, 400)\n",
    "\n",
    "# Evaluate using test_set\n",
    "y_hat = model.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "rmse_0 = np.sqrt(mean_squared_error(y_test,y_hat))\n",
    "r2_0 = r2_score(y_test,y_hat)\n",
    "\n",
    "print(f\"RMSE metrics: {rmse_0}\")\n",
    "print(f\"R2 metrics: {r2_0}\")\n"
   ]
  },
  {
   "source": [
    "Show how to scale features, train new  model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[-0.42842136 -0.99913445 -0.37792992]\n [ 0.22190846 -0.87653898 -1.10379239]\n [-1.52097544 -1.34688122  1.79965748]\n ...\n [ 0.14386888 -0.03841032  0.31163942]\n [-0.32436858 -0.13271453  0.31163942]\n [ 0.19589527 -0.16807861 -0.30534367]]\nX_train\n[[-1.07875117e+00 -1.09225986e+00  5.29398160e-01]\n [-1.94302622e-01 -6.74963731e-01 -2.32757428e-01]\n [ 5.34066770e-01  7.39599403e-01 -1.96464305e-01]\n [-6.10513703e-01 -8.93042214e-01  4.93105037e-01]\n [-6.36526896e-01 -9.59055160e-01 -1.96464305e-01]\n [-5.06460933e-01 -4.60421656e-01  1.66466928e-01]\n [-5.06460933e-01  1.46357967e-02  9.64915640e-01]\n [ 1.70466044e+00  1.99266658e+00 -1.46672362e+00]\n [-5.32474126e-01 -5.74765509e-01  5.75875579e-02]\n [ 7.94198696e-01  1.00482999e+00 -1.23878059e-01]\n [ 6.64132733e-01  1.55297320e+00 -2.32757428e-01]\n [ 1.43868881e-01  6.39401181e-01  3.11639421e-01]\n [-1.31286990e+00 -8.52962925e-01  2.88845117e+00]\n [ 1.05433062e+00  1.37025880e+00 -6.68274908e-01]\n [-1.33888310e+00 -1.39403332e+00  7.10863777e-01]\n [-5.32474126e-01 -5.33507418e-01  1.66466928e-01]\n [ 9.24264659e-01  1.55179440e+00  1.66466928e-01]\n [-9.48685207e-01 -1.17006083e+00  1.66466928e-01]\n [-8.44632436e-01  5.35666551e-01  1.98112309e+00]\n [ 9.24264659e-01  1.37143760e+00 -5.59395538e-01]\n [-1.15679075e+00 -1.38813931e+00  3.11639421e-01]\n [-2.46329007e-01 -8.67412279e-02  1.66466928e-01]\n [ 1.43868881e-01  1.09559779e+00  1.98112309e+00]\n [ 3.13538603e+00  1.27800847e-01 -2.01112047e+00]\n [-2.46329007e-01  2.53932727e-01  8.19743147e-01]\n [-9.74698399e-01 -1.07575662e+00  8.19743147e-01]\n [ 1.31446255e+00  1.62959537e+00 -2.32757428e-01]\n [ 1.83472640e+00  1.75219085e+00 -1.46672362e+00]\n [ 2.73934844e-01 -4.50991235e-01 -1.53930987e+00]\n [-3.24368585e-01 -4.62779261e-01 -3.77929921e-01]\n [-8.44632436e-01 -6.79678941e-01  1.43672624e+00]\n [ 1.43868881e-01 -4.45097222e-01 -9.94913017e-01]\n [-8.96658822e-01 -1.21721293e+00  4.56811914e-01]\n [-9.48685207e-01 -1.09933267e+00  1.07379501e+00]\n [-8.70645629e-01  2.50396319e-01  3.36026178e+00]\n [-6.62540088e-01 -4.15627156e-01  1.11008813e+00]\n [ 3.00532006e+00  1.62252256e+00 -2.37405170e+00]\n [-4.80447740e-01 -2.21124726e-01  2.12944346e-02]\n [-4.28421355e-01  3.44700528e-01  2.30776120e+00]\n [ 1.95895267e-01 -1.68078608e-01 -3.05343675e-01]\n [-6.88553281e-01 -4.54527643e-01  1.07379501e+00]\n [ 1.38029185e-02  7.49029824e-01  3.47932544e-01]\n [-7.66592859e-01 -9.04830240e-01 -4.14223045e-01]\n [-4.80447740e-01 -8.85969398e-01  3.47932544e-01]\n [-4.02408163e-01 -2.62382817e-01  9.38806811e-02]\n [ 1.18439658e+00  9.16419794e-01 -5.59395538e-01]\n [-1.94302622e-01 -2.39985567e-01 -1.49986887e-02]\n [ 1.38029185e-02  1.69058939e-01  3.47932544e-01]\n [ 9.76291044e-01  1.26888178e+00 -4.50516168e-01]\n [-1.02672478e+00 -1.09933267e+00  2.39053174e-01]\n [-9.74698399e-01 -9.81452410e-01  8.92329393e-01]\n [ 2.22492429e+00  1.02840604e+00 -2.55551732e+00]\n [ 2.73934844e-01 -3.61402236e-01 -7.40861154e-01]\n [ 1.43868881e-01  8.86949729e-01  1.25526063e+00]\n [-1.02672478e+00 -1.41996698e+00  1.25526063e+00]\n [ 1.70466044e+00  1.97616334e+00 -9.22326771e-01]\n [-1.02672478e+00 -1.02271050e+00  1.32784687e+00]\n [ 3.26545199e+00  1.53293356e+00 -2.19258609e+00]\n [ 4.04000807e-01 -5.60923600e-02 -6.31981784e-01]\n [ 1.43868881e-01 -3.03640908e-01 -7.40861154e-01]\n [-2.46329007e-01  9.51783873e-01  1.25526063e+00]\n [ 1.83472640e+00  1.32310670e+00 -9.22326771e-01]\n [-4.28421355e-01 -3.97945117e-01  1.11008813e+00]\n [ 1.62662086e+00  2.27322160e+00 -1.10379239e+00]\n [ 1.38029185e-02  1.08380977e+00  1.07379501e+00]\n [ 1.18439658e+00  1.75219085e+00 -1.28525800e+00]\n [-4.28421355e-01 -1.03244464e-01  6.38277530e-01]\n [-7.66592859e-01 -5.13467773e-01  5.29398160e-01]\n [ 1.05433062e+00  5.27414933e-01 -8.49740524e-01]\n [-9.74698399e-01 -1.15237879e+00  1.66466928e-01]\n [-2.20315815e-01 -3.24859355e-01 -7.40861154e-01]\n [ 5.34066770e-01  1.08734617e+00  6.74570654e-01]\n [ 9.24264659e-01  1.29953064e+00 -6.68274908e-01]\n [-2.98355392e-01 -6.91466967e-01 -1.49986887e-02]\n [-3.76394970e-01 -8.41174899e-01 -1.49986887e-02]\n [-7.66592859e-01 -9.10724253e-01 -3.77929921e-01]\n [-3.76394970e-01 -1.00738607e+00 -5.59395538e-01]\n [ 9.18424962e-02 -5.60923600e-02 -1.49986887e-02]\n [ 1.95895267e-01 -1.29178122e-01 -1.49986887e-02]\n [-3.76394970e-01 -8.39996096e-01 -1.49986887e-02]\n [-8.70645629e-01 -1.16416681e+00 -2.32757428e-01]\n [-8.96658822e-01 -1.16416681e+00  5.29398160e-01]\n [-3.76394970e-01 -4.96964537e-01 -8.49740524e-01]\n [-4.28421355e-01 -4.39203209e-01  1.47301937e+00]\n [-5.58487318e-01 -1.06396859e+00  1.30173804e-01]\n [ 2.99948037e-01 -9.14564383e-02 -1.06749926e+00]\n [ 1.18439658e+00  1.48460265e+00 -3.77929921e-01]\n [-1.16263044e-01  3.65918975e-01 -1.49986887e-02]\n [-2.20315815e-01 -3.68475052e-01 -5.95688661e-01]\n [-9.48685207e-01 -9.93240436e-01  3.84225667e-01]\n [-8.96658822e-01 -9.16618266e-01 -8.49740524e-01]\n [ 1.18439658e+00  1.07791575e+00 -1.10379239e+00]\n [-1.94302622e-01 -5.75944312e-01 -1.96464305e-01]\n [-4.28421355e-01 -6.86751757e-01  8.92329393e-01]\n [-1.94302622e-01 -7.98738005e-01 -3.05343675e-01]\n [-1.16263044e-01  3.01084831e-01 -5.12918120e-02]\n [-9.22672014e-01 -1.60857540e+00  8.92329393e-01]\n [-1.02672478e+00 -1.18184885e+00 -1.23878059e-01]\n [-6.36526896e-01  2.97548423e-01  1.76336435e+00]\n [ 1.57459447e+00  1.45159618e+00 -1.28525800e+00]\n [ 1.38029185e-02 -2.09336699e-01 -4.14223045e-01]\n [-1.16263044e-01 -4.27415183e-01 -2.69050552e-01]\n [ 2.48505621e+00  1.64845622e+00 -1.96464305e-01]\n [-1.52097544e+00 -1.34688122e+00  1.79965748e+00]\n [-6.88553281e-01 -9.30763898e-01  9.38806811e-02]\n [-1.94302622e-01 -5.09931365e-01  5.29398160e-01]\n [-6.42366592e-02  2.03244215e-01  5.75875579e-02]\n [-5.32474126e-01 -7.16221822e-01 -9.22326771e-01]\n [ 4.04000807e-01  9.93041964e-01  4.20518791e-01]\n [-7.66592859e-01 -1.02506811e+00 -1.49986887e-02]\n [-6.36526896e-01 -9.69664384e-01 -2.69050552e-01]\n [ 1.70466044e+00  1.39972886e+00 -1.50301674e+00]\n [-3.76394970e-01  2.73972371e-01  6.01984407e-01]\n [ 8.98251466e-01  2.68078358e-01 -1.57560299e+00]\n [-7.66592859e-01 -8.39996096e-01  9.64915640e-01]\n [-4.28421355e-01 -9.99134449e-01 -3.77929921e-01]\n [-5.06460933e-01  1.08940006e-01  4.20518791e-01]\n [-9.48685207e-01 -9.69664384e-01  3.47932544e-01]\n [ 1.44452851e+00  7.44314613e-01 -2.73698293e+00]\n [-1.16263044e-01  5.33308946e-01  6.01984407e-01]\n [ 1.43868881e-01 -1.83706764e-02 -7.40861154e-01]\n [-2.20315815e-01 -7.98738005e-01 -1.49986887e-02]\n [-5.58487318e-01 -8.94221017e-01  3.47932544e-01]\n [ 4.56027192e-01 -2.01085081e-01 -7.40861154e-01]\n [ 2.87525410e+00  2.07164635e+00 -1.64818924e+00]\n [-2.46329007e-01  3.37627712e-01  1.66466928e-01]\n [ 1.43868881e-01  7.57281442e-01  1.14638126e+00]\n [-9.74698399e-01  3.21124476e-01  2.27146808e+00]\n [-8.44632436e-01 -6.71427323e-01  1.25526063e+00]\n [ 1.70466044e+00  6.90089693e-01 -2.01112047e+00]\n [-9.22672014e-01 -9.99134449e-01 -3.05343675e-01]\n [ 1.31446255e+00  1.79698534e+00 -7.40861154e-01]\n [ 1.05433062e+00  1.06377012e+00 -1.10379239e+00]\n [ 1.43868881e-01  1.27595459e+00  1.25526063e+00]\n [ 1.18439658e+00  8.18579178e-01 -1.46672362e+00]\n [ 9.24264659e-01  5.55706195e-01 -1.82965485e+00]\n [-3.76394970e-01  2.99602307e-02  1.65448498e+00]\n [ 6.64132733e-01  1.05198209e+00 -1.96464305e-01]\n [-9.74698399e-01 -1.19363688e+00  5.75875579e-02]\n [-4.28421355e-01 -1.26820517e-01  9.28622516e-01]\n [-2.46329007e-01 -3.34289776e-01 -1.96464305e-01]\n [-1.16263044e-01  3.54130949e-01  8.92329393e-01]\n [-1.68289430e-01 -3.84103208e-02 -3.77929921e-01]\n [ 2.69316175e+00  1.95140849e+00 -1.64818924e+00]\n [-6.62540088e-01 -8.51784123e-01  7.83450023e-01]\n [ 1.43868881e-01 -3.84103208e-02  3.11639421e-01]\n [ 3.13538603e+00  2.32626772e+00 -1.64818924e+00]\n [ 2.22492429e+00  1.58833728e+00 -1.21267176e+00]\n [-8.44632436e-01 -4.86355313e-01 -7.04568031e-01]\n [ 4.04000807e-01  1.16043193e+00 -5.95688661e-01]\n [-9.48685207e-01 -1.12290872e+00  9.64915640e-01]\n [ 8.46225081e-01  1.25473614e+00 -3.77929921e-01]\n [ 1.18439658e+00  2.02920946e+00 -3.77929921e-01]\n [-5.58487318e-01 -3.99123920e-01  5.29398160e-01]\n [-8.96658822e-01 -1.22664335e+00 -5.59395538e-01]\n [ 1.18439658e+00  9.23492610e-01 -2.19258609e+00]\n [-3.82234666e-02 -1.73972621e-01  1.30173804e-01]\n [ 1.26243616e+00  1.35729197e+00 -9.22326771e-01]\n [ 1.18439658e+00  8.18579178e-01 -1.46672362e+00]\n [ 7.16159118e-01 -7.96684122e-02 -1.50301674e+00]\n [ 1.96479236e+00  1.65317143e+00 -1.24896488e+00]\n [-1.20881713e+00 -1.44118543e+00  4.93105037e-01]\n [-2.46329007e-01  1.46661689e-01  3.47932544e-01]\n [ 1.15838339e+00  1.60012531e+00 -3.77929921e-01]\n [-3.76394970e-01 -2.85958869e-01  8.92329393e-01]\n [-2.46329007e-01 -7.10327809e-01  7.10863777e-01]\n [-5.06460933e-01 -7.86949979e-01  1.07379501e+00]\n [ 1.18439658e+00  5.36845353e-01 -1.28525800e+00]\n [-2.46329007e-01 -8.24671663e-01 -1.49986887e-02]\n [ 1.96479236e+00  1.46456301e+00 -1.61189611e+00]\n [-4.54434548e-01  1.66896798e-03  1.43672624e+00]\n [-1.15679075e+00 -1.19010047e+00  1.18267438e+00]\n [-7.66592859e-01 -8.81254188e-01 -3.77929921e-01]\n [-3.76394970e-01  1.26622045e-01  7.47156900e-01]\n [-8.70645629e-01 -8.89505806e-01  3.47932544e-01]\n [-9.74698399e-01 -1.15827280e+00  2.39053174e-01]\n [ 6.38119540e-01  8.81055716e-01 -7.77154277e-01]\n [ 1.57459447e+00  8.43334032e-01 -1.46672362e+00]\n [-4.28421355e-01 -2.80064856e-01  1.66466928e-01]\n [ 1.18439658e+00  1.13449828e+00 -9.22326771e-01]\n [-4.54434548e-01 -3.60223434e-01  7.10863777e-01]\n [-1.46894906e+00 -1.05218057e+00  2.23517495e+00]\n [-1.02672478e+00 -1.34570242e+00  1.98112309e+00]\n [ 2.22492429e+00  1.70268114e+00 -1.10379239e+00]\n [-1.36489629e+00 -1.11112070e+00  2.41664057e+00]\n [ 2.73934844e-01  3.15230463e-01 -5.12918120e-02]\n [-7.92606051e-01 -1.17595484e+00 -8.75849353e-02]\n [-3.76394970e-01 -3.25163077e-02  6.38277530e-01]\n [-8.70645629e-01 -1.35866925e+00 -1.21267176e+00]\n [-7.40579666e-01  2.15032241e-01  1.47301937e+00]\n [ 6.64132733e-01  1.32074909e+00 -5.59395538e-01]\n [-2.46329007e-01 -5.45295444e-01 -2.69050552e-01]\n [ 6.64132733e-01  6.20540339e-01 -1.28525800e+00]\n [-3.76394970e-01  3.38806515e-01  9.64915640e-01]\n [-1.52097544e+00 -1.21131892e+00  1.98112309e+00]\n [ 1.43868881e-01  4.56686776e-01 -1.49986887e-02]\n [-1.15679075e+00 -1.34806002e+00  1.25526063e+00]\n [-8.96658822e-01 -8.63572149e-01  4.93105037e-01]\n [-4.28421355e-01 -1.03449853e+00  3.47932544e-01]\n [-1.16263044e-01  3.58846159e-01 -1.96464305e-01]\n [ 1.38029185e-02  6.57083220e-01  1.32784687e+00]\n [ 1.26243616e+00  1.38676204e+00 -7.40861154e-01]\n [ 1.23642297e+00  1.45866900e+00 -9.94913017e-01]\n [-7.40579666e-01 -9.82631212e-01 -3.05343675e-01]\n [-1.46894906e+00 -7.57479914e-01  2.96103742e+00]\n [-7.66592859e-01 -5.13467773e-01  7.10863777e-01]\n [ 1.96479236e+00  8.09148757e-01 -1.64818924e+00]\n [-6.88553281e-01 -1.22310695e+00 -3.77929921e-01]\n [-1.94302622e-01 -5.55904667e-01 -3.77929921e-01]\n [ 1.43868881e-01  4.50792763e-01  3.84225667e-01]\n [-7.66592859e-01 -1.00502846e+00 -3.77929921e-01]\n [-5.58487318e-01 -9.14260661e-01 -8.75849353e-02]\n [ 2.87525410e+00  1.57301285e+00 -2.55551732e+00]\n [-1.16263044e-01 -4.05017933e-01 -9.22326771e-01]\n [-4.28421355e-01 -9.99134449e-01 -3.77929921e-01]\n [ 1.43868881e-01  7.86751507e-01  2.39053174e-01]\n [-1.16263044e-01 -6.57281692e-01 -1.10379239e+00]\n [-4.28421355e-01  5.11786777e-02  3.47932544e-01]\n [-5.06460933e-01 -4.74567287e-01  2.39053174e-01]\n [ 1.13237020e+00  1.97969975e+00 -7.40861154e-01]\n [ 1.38029185e-02 -2.74170843e-01  4.20518791e-01]\n [-3.50381778e-01 -4.66315669e-01 -5.59395538e-01]\n [-5.06460933e-01  5.74567037e-01  3.84225667e-01]\n [-4.28421355e-01 -8.23492860e-01  1.25526063e+00]\n [-7.92606051e-01 -9.28406292e-01 -4.86809291e-01]\n [-1.94302622e-01  7.56298104e-03 -3.77929921e-01]\n [-1.94302622e-01 -7.63373927e-01 -7.40861154e-01]\n [ 8.72238274e-01  1.15218032e+00 -8.49740524e-01]\n [ 1.38029185e-02  5.43918169e-01 -1.49986887e-02]\n [ 1.18439658e+00  1.42919893e+00 -9.22326771e-01]\n [-6.36526896e-01 -1.25257701e+00 -4.14223045e-01]\n [-1.94302622e-01 -1.91654660e-01 -3.77929921e-01]\n [ 9.24264659e-01  1.95730250e+00  1.66466928e-01]\n [ 1.43868881e-01  7.71427073e-01  8.92329393e-01]\n [-1.33888310e+00 -1.39403332e+00  6.74570654e-01]\n [-6.36526896e-01 -6.20738811e-01  3.47932544e-01]\n [-5.32474126e-01 -6.98539783e-01 -9.58619894e-01]\n [-3.24368585e-01 -1.32714530e-01  3.11639421e-01]\n [-2.46329007e-01  2.09138228e-01  9.64915640e-01]\n [ 9.24264659e-01  1.45866900e+00 -9.22326771e-01]\n [-1.44293587e+00 -1.30915954e+00  1.43672624e+00]\n [ 1.96479236e+00  1.79344894e+00 -1.10379239e+00]\n [-4.28421355e-01 -9.63770371e-01 -3.77929921e-01]\n [ 1.43868881e-01 -2.97746895e-01 -1.06749926e+00]\n [ 6.58293037e-02 -5.95983956e-01 -5.59395538e-01]\n [ 1.44452851e+00  1.74276042e+00 -7.40861154e-01]\n [ 9.24264659e-01  8.92843742e-01 -8.49740524e-01]\n [ 2.43302983e+00  2.32744652e+00 -1.46672362e+00]\n [-7.14566474e-01  6.51189207e-01  1.65448498e+00]\n [-3.24368585e-01 -8.12883636e-01  5.29398160e-01]\n [-8.44632436e-01 -8.10526031e-01  5.29398160e-01]\n [ 2.73934844e-01 -2.15230712e-01  5.75875579e-02]\n [-7.92606051e-01 -4.03839130e-01  1.00120876e+00]\n [-4.28421355e-01  3.82422211e-01 -1.49986887e-02]\n [ 1.05433062e+00  1.30188825e+00 -9.22326771e-01]\n [ 4.04000807e-01  5.09732893e-01 -1.60171182e-01]\n [-7.66592859e-01 -7.39797875e-01  4.56811914e-01]\n [-2.46329007e-01 -8.83611793e-01 -5.59395538e-01]\n [ 1.83472640e+00  2.54906141e+00 -1.28525800e+00]\n [-1.07875117e+00 -8.98936227e-01 -2.32757428e-01]\n [-1.36489629e+00 -1.56613850e+00  3.47932544e-01]\n [ 2.73934844e-01 -3.27216961e-01 -9.58619894e-01]\n [ 2.30296387e+00  2.06810995e+00  1.07379501e+00]\n [-8.96658822e-01 -1.22664335e+00 -4.86809291e-01]\n [ 1.43868881e-01  2.86939200e-01 -7.40861154e-01]\n [-7.66592859e-01 -9.50803542e-01  1.66466928e-01]\n [-1.00071159e+00 -1.38813931e+00 -4.14223045e-01]\n [-6.88553281e-01  7.03056522e-01  1.98112309e+00]\n [-7.40579666e-01 -1.07575662e+00 -3.77929921e-01]\n [-8.96658822e-01 -1.06514740e+00  1.43672624e+00]\n [-9.74698399e-01 -1.21131892e+00  1.25526063e+00]\n [-4.80447740e-01 -6.05414377e-01 -1.49986887e-02]\n [-1.07875117e+00 -1.00502846e+00 -3.05343675e-01]\n [-6.36526896e-01 -3.62581039e-01 -1.96464305e-01]\n [-5.32474126e-01 -4.03839130e-01  3.11639421e-01]\n [ 1.18439658e+00  1.50817871e+00 -1.49986887e-02]\n [-1.02672478e+00 -1.12880274e+00  1.32784687e+00]\n [-1.36489629e+00 -9.99134449e-01  3.28767553e+00]\n [-8.44632436e-01  2.12674635e-01  1.43672624e+00]\n [-1.16263044e-01 -3.84103208e-02  1.66466928e-01]\n [-1.15679075e+00 -1.43529142e+00  2.02760051e-01]\n [-1.05273798e+00 -1.29972911e+00  3.11639421e-01]\n [-1.16263044e-01  7.93824323e-01  7.83450023e-01]\n [-8.96658822e-01 -1.06986261e+00  1.11008813e+00]\n [ 1.39250213e+00  1.63313178e+00 -9.22326771e-01]\n [-5.06460933e-01 -1.48342686e-02  9.38806811e-02]\n [ 1.18439658e+00  1.36436479e+00 -7.40861154e-01]\n [-3.76394970e-01  4.75547618e-01  1.14638126e+00]\n [ 2.74518814e+00  1.65552903e+00 -7.40861154e-01]\n [-3.76394970e-01  2.75151174e-01  5.29398160e-01]\n [-1.02672478e+00 -1.18184885e+00  1.40043312e+00]\n [-5.32474126e-01 -8.04632018e-01 -1.43043050e+00]\n [ 1.05433062e+00  1.72389958e+00 -5.59395538e-01]\n [-5.84500511e-01 -3.03640908e-01  1.40043312e+00]\n [-4.80447740e-01 -8.93042214e-01 -5.59395538e-01]\n [-6.10513703e-01  4.05694542e-02  7.47156900e-01]\n [-1.02672478e+00 -1.12998154e+00  3.11639421e-01]\n [-7.66592859e-01 -9.66127976e-01 -1.49986887e-02]\n [ 1.95895267e-01 -5.25559521e-02 -3.77929921e-01]\n [ 1.43868881e-01 -3.74369065e-01 -5.59395538e-01]\n [-3.76394970e-01  5.21520920e-01  2.41664057e+00]\n [-1.46894906e+00 -1.17006083e+00  2.16258871e+00]\n [ 7.42172311e-01  5.09732893e-01  9.38806811e-02]\n [ 1.18439658e+00  1.13449828e+00 -8.49740524e-01]\n [-3.76394970e-01 -3.88514696e-01 -1.96464305e-01]\n [ 1.43868881e-01  5.15626906e-01  9.38806811e-02]\n [ 1.38029185e-02  4.42541145e-01 -3.77929921e-01]\n [-2.46329007e-01 -4.92249326e-01 -4.86809291e-01]\n [-8.96658822e-01 -1.01092248e+00 -1.49986887e-02]\n [-1.15679075e+00 -9.59055160e-01  2.38034745e+00]\n [ 1.05433062e+00  1.19108080e+00 -9.22326771e-01]\n [-1.16263044e-01  4.14249882e-01 -1.49986887e-02]\n [ 1.18439658e+00  1.79227013e+00 -3.77929921e-01]]\nX in class\n[[ 1.         -1.07875117 -1.09225986  0.52939816]\n [ 1.         -0.19430262 -0.67496373 -0.23275743]\n [ 1.          0.53406677  0.7395994  -0.19646431]\n ...\n [ 1.          1.05433062  1.1910808  -0.92232677]\n [ 1.         -0.11626304  0.41424988 -0.01499869]\n [ 1.          1.18439658  1.79227013 -0.37792992]]\nRMSE metrics: 16.924667458559014\nR2 metrics: -3.1563972768816733\n"
     ]
    }
   ],
   "source": [
    "# Do a model comparison\n",
    "scaler = StandardScaler()\n",
    "X_norm = scaler.fit_transform(X)\n",
    "\n",
    "# X_norm2 = np.concatenate([np.ones((X_norm.shape[0], 1)), X_norm], axis=1)\n",
    "\n",
    "print(X_norm)\n",
    "\n",
    "# Split test and Train sets\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_norm, y, test_size=0.2, random_state=0)\n",
    "\n",
    "print(\"X_train\")\n",
    "print(X_train2)\n",
    "\n",
    "# Train model with unscaled features\n",
    "# model2 = LinearRegression(normalize=False)\n",
    "# model2.fit(X_train,y_train)\n",
    "model2 = slr.SimpleLinearRegression()\n",
    "_, J_history2 = model2.fit(X_train2,y_train2, 0.001, 400)\n",
    "\n",
    "# Evaluate using test_set\n",
    "y_hat2 = model2.predict(X_test2)\n",
    "\n",
    "# Calculate metrics\n",
    "rmse_1 = np.sqrt(mean_squared_error(y_test,y_hat2))\n",
    "r2_1 = r2_score(y_test2,y_hat2)\n",
    "\n",
    "print(f\"RMSE metrics: {rmse_1}\")\n",
    "print(f\"R2 metrics: {r2_1}\")\n",
    "\n",
    "# # Use a dataframe to create a comparison table of metrics\n",
    "# l = [[\"Unscaled Features\", original_rmse, original_r2],\n",
    "#     [\"Custom Model\", rmse, r2]]\n",
    "\n",
    "# pd.DataFrame(l, columns=[\"\", \"RMSE\", \"R2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "axes = fig.add_subplot()\n",
    "axes.set_title('Cost x Iterations for Different Learning Rates')\n",
    "\n",
    "l0 = plt.plot(np.arange(len(J_history)), J_history, lw=2, color=\"red\")\n",
    "l1 = plt.plot(np.arange(len(J_history2)), J_history2, lw=2, color=\"blue\")\n",
    "\n",
    "# Add legend\n",
    "red_patch = mpatches.Patch(color=\"red\", label=\"High\")\n",
    "blue_patch = mpatches.Patch(color=\"blue\", label=\"Low\")\n",
    "plt.legend(title = \"Learning Rate\", handles=[red_patch, blue_patch])\n",
    "plt.xlabel(\"Number of iterations\")\n",
    "_ = plt.ylabel(\"Cost\")"
   ]
  },
  {
   "source": [
    "Conclusion"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "\n",
    "\n",
    "## Summary\n",
    "\n",
    ".....\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}