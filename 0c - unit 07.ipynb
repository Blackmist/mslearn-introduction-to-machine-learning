{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "pythonjvsc74a57bd05fd7d2d989b956829c9ad45cc6f2d78f0054d35d23dba8942e8fbd9b2870e6f3",
   "display_name": "Python 3.8.5  ('venv': venv)"
  },
  "metadata": {
   "interpreter": {
    "hash": "5fd7d2d989b956829c9ad45cc6f2d78f0054d35d23dba8942e8fbd9b2870e6f3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Exercise: Titanic Dataset - One-Hot Vectors\n",
    "\n",
    "- Load cleaned dataset\n",
    "- Explain 1-hot vectors\n",
    "- 1-hot a categorical value\n",
    "- Build a model, compare to previous results\n",
    "\n",
    "\n",
    "## Preparing data\n",
    "\n",
    "This time we start by using the \"cleaned\" dataset we saved in Unit 5:\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 889 entries, 0 to 888\nData columns (total 12 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   PassengerId  889 non-null    int64  \n 1   Survived     889 non-null    int64  \n 2   Pclass       889 non-null    int64  \n 3   Name         889 non-null    object \n 4   Sex          889 non-null    object \n 5   Age          889 non-null    float64\n 6   SibSp        889 non-null    int64  \n 7   Parch        889 non-null    int64  \n 8   Ticket       889 non-null    object \n 9   Fare         889 non-null    float64\n 10  Cabin        889 non-null    object \n 11  Embarked     889 non-null    object \ndtypes: float64(2), int64(5), object(5)\nmemory usage: 83.5+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data from our dataset file into a pandas dataframe\n",
    "dataset = pd.read_csv('Data/Cleaned_Titanic.csv', index_col=False, sep=\",\",header=0)\n",
    "\n",
    "# Make sure we don't have missing values\n",
    "dataset.info()\n"
   ]
  },
  {
   "source": [
    "The dataset has 12 columns and 889 non-null (not empty) values. We are good to go!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## One-Hot Encoding\n",
    "In the previous Unit we had to disregard all **Categorical** data because it wasn't ready to be processed by our `Logistic Regression` algorithm, as it requires all input values to be numerical.\n",
    "\n",
    "But that is a lot of valuable data that we can easily integrate into our model, if we can represent it (or encode it) in a format that the algorithm understands.\n",
    "\n",
    "One way to address that is to use a technique called \"One-Hot Encoding\", where we create a new column for each possible category and set the value to \"1\" **only** where that category describes the entry (leaving it as zero otherwise).\n",
    "\n",
    "Let's try to visualize it:\n",
    "\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Possible values for Embarked: ['S' 'C' 'Q']\n"
     ]
    }
   ],
   "source": [
    "# Get all possible categories for the \"Embarked\" column\n",
    "print(f\"Possible values for Embarked: {dataset['Embarked'].unique()}\")"
   ]
  },
  {
   "source": [
    "We have three possible values for the port where the passenger embarked: \n",
    "\n",
    "- S = Southampton\n",
    "- C = Cherbourg, \n",
    "- Q = Queenstown, \n",
    "\n",
    "\n",
    "The code above conveniently arranged those options as a three valued \"ports vector\":\n",
    "\n",
    "\n",
    "`['S' 'C' 'Q']`\n",
    "\n",
    "To One-Hot encode the dataset:\n",
    "\n",
    "1. For each possible value, create a column.\n",
    "\n",
    "2. Assign \"1\" **only** to the column corresponding to the entry's category:\n",
    "\n",
    "\n",
    "| PassengerId \t| Name                                              \t| Embarked \t| Embarked_S \t| Embarked_Q \t| Embarked_C \t|\n",
    "|-------------\t|---------------------------------------------------\t|:--------:\t|:----------:\t|:----------:\t|:----------:\t|\n",
    "| 1           \t| Braund, Mr. Owen Harris                           \t|     S    \t|      1     \t|      0     \t|      0     \t|\n",
    "| 2           \t| Cumings, Mrs. John Bradley (Florence Briggs Th... \t|     Q    \t|      0     \t|      1     \t|      0     \t|\n",
    "\n",
    "Above, Mr. Braund embarked on por \"S\", therefore only that column is marked as \"1\"\n",
    "\n",
    "We can use One-Hot encoding for the \"Sex\" category as well.\n",
    "\n",
    "\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Possible values for Sex: ['male' 'female']\n"
     ]
    }
   ],
   "source": [
    "# Get all possible categories for the \"Sex\" column\n",
    "print(f\"Possible values for Sex: {dataset['Sex'].unique()}\")"
   ]
  },
  {
   "source": [
    "| PassengerId \t| Name                                              \t| Sex    \t| Sex_m \t| Sex_f \t|\n",
    "|-------------\t|---------------------------------------------------\t|--------\t|:-----:\t|:-----:\t|\n",
    "| 1           \t| Braund, Mr. Owen Harris                           \t| male   \t|   1   \t|   0   \t|\n",
    "| 2           \t| Cumings, Mrs. John Bradley (Florence Briggs Th... \t| female \t|   0   \t|   1   \t|\n",
    "\n",
    "Passenger class\" is represented numerically in this dataset, and although we could possibly use it \"as is\", it will treat it as categorical data and \"One-Hot\" encode it was well:\n",
    "\n",
    "\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Possible values for Pclass: [3 1 2]\n"
     ]
    }
   ],
   "source": [
    "# Get all possible categories for the \"Pclass\" column\n",
    "print(f\"Possible values for Pclass: {dataset['Pclass'].unique()}\")"
   ]
  },
  {
   "source": [
    "| PassengerId \t| Name                                              \t| Pclass \t| Pclass_1 \t| Pclass_2 \t| Pclass_3 \t|\n",
    "|-------------\t|---------------------------------------------------\t|:------:\t|:--------:\t|:--------:\t|:--------:\t|\n",
    "| 1           \t| Braund, Mr. Owen Harris                           \t|    3   \t|     0    \t|     0    \t|     1    \t|\n",
    "| 2           \t| Cumings, Mrs. John Bradley (Florence Briggs Th... \t|    1   \t|     1    \t|     0    \t|     0    \t|\n",
    "\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Possible options for Cabin: (147,)\n"
     ]
    }
   ],
   "source": [
    "# Justb out of curiosity, how many options do we have for the \"Cabin\" category\n",
    "print(f\"Possible options for Cabin: {dataset['Cabin'].unique().shape}\")"
   ]
  },
  {
   "source": [
    "Using numerical `vectors` to describe categories allows us to use that information in most Machine Learning algorithms.\n",
    "\n",
    "## Building a new model\n",
    "\n",
    "Let's build a new model, using the cleaned dataset from the previous Unit (where we addressed missing values), but making sure we include the categorical columns this time.\n",
    "\n",
    "We need to one-hot encode the following columns:\n",
    "\n",
    "- Pclass\n",
    "- Sex\n",
    "- Cabin\n",
    "- Embarked"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Survived   Age  SibSp  Parch     Fare  Pclass_1  Pclass_2  Pclass_3  \\\n",
       "0         0  22.0      1      0   7.2500         0         0         1   \n",
       "1         1  38.0      1      0  71.2833         1         0         0   \n",
       "2         1  26.0      0      0   7.9250         0         0         1   \n",
       "3         1  35.0      1      0  53.1000         1         0         0   \n",
       "4         0  35.0      0      0   8.0500         0         0         1   \n",
       "\n",
       "   Sex_female  Sex_male  ...  Cabin_F2  Cabin_F33  Cabin_F38  Cabin_F4  \\\n",
       "0           0         1  ...         0          0          0         0   \n",
       "1           1         0  ...         0          0          0         0   \n",
       "2           1         0  ...         0          0          0         0   \n",
       "3           1         0  ...         0          0          0         0   \n",
       "4           0         1  ...         0          0          0         0   \n",
       "\n",
       "   Cabin_G6  Cabin_T  Cabin_Unknown  Embarked_C  Embarked_Q  Embarked_S  \n",
       "0         0        0              1           0           0           1  \n",
       "1         0        0              0           1           0           0  \n",
       "2         0        0              1           0           0           1  \n",
       "3         0        0              0           0           0           1  \n",
       "4         0        0              1           0           0           1  \n",
       "\n",
       "[5 rows x 160 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Survived</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n      <th>Pclass_1</th>\n      <th>Pclass_2</th>\n      <th>Pclass_3</th>\n      <th>Sex_female</th>\n      <th>Sex_male</th>\n      <th>...</th>\n      <th>Cabin_F2</th>\n      <th>Cabin_F33</th>\n      <th>Cabin_F38</th>\n      <th>Cabin_F4</th>\n      <th>Cabin_G6</th>\n      <th>Cabin_T</th>\n      <th>Cabin_Unknown</th>\n      <th>Embarked_C</th>\n      <th>Embarked_Q</th>\n      <th>Embarked_S</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7.2500</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>71.2833</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.9250</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>53.1000</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.0500</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 160 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 844
    }
   ],
   "source": [
    "import sklearn.model_selection as model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "# Let's remove some fields that are not needed right now\n",
    "dataset = dataset.drop([\"PassengerId\",\"Name\",\"Ticket\"], axis=1)\n",
    "\n",
    "# Generate One-Hot encodings for the categorical columns\n",
    "complete_dataset = pd.get_dummies(dataset, columns=[\"Pclass\", \"Sex\", \"Cabin\", \"Embarked\"], drop_first=False)\n",
    "\n",
    "# Check resulting dataset\n",
    "complete_dataset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(889, 9)"
      ]
     },
     "metadata": {},
     "execution_count": 845
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "source": [
    "The One-Hot encoded dataset now has 160 columns (remember that we had 147 categories for the field \"Cabin\" alone, plus several different possibilities for each other categorical field).\n",
    "\n",
    "We can now train and evaluate our new model using the \"complete\" dataset:\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X is our feature matrix\n",
    "X = complete_dataset.drop([\"Survived\"], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# y is the label vector \n",
    "y = complete_dataset[\"Survived\"]\n",
    "\n",
    "# Create Train and test sets with a 70/30 split\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, train_size=0.70,test_size=0.30, random_state=101)\n",
    "\n",
    "# train the model (increase then # of maximum iterations for the new dataset)\n",
    "model = LogisticRegression(random_state=0, max_iter=2000).fit(X_train, y_train)\n",
    "\n",
    "# score is the mean accuracy on the given test data and labels\n",
    "score = model.score(X_train, y_train)\n",
    "\n",
    "# calculate loss\n",
    "probabilities = model.predict_proba(X_test)\n",
    "loss = metrics.log_loss(y_test, probabilities)\n",
    "\n",
    "# save results for comparison\n",
    "complete_score = score\n",
    "complete_loss = loss\n",
    "\n"
   ]
  },
  {
   "source": [
    "## Comparing Models\n",
    "\n",
    "We can compare the  `score` and `loss` metrics for this model with the metrics we gathered in Unit 5:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                   Dataset     Score      Loss\n",
       "0    Numeric Features Only  0.696141  0.609630\n",
       "1  Numeric and categorical  0.826367  0.425014"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Dataset</th>\n      <th>Score</th>\n      <th>Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Numeric Features Only</td>\n      <td>0.696141</td>\n      <td>0.609630</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Numeric and categorical</td>\n      <td>0.826367</td>\n      <td>0.425014</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 847
    }
   ],
   "source": [
    "# Use a dataframe to create a comparison table of metrics\n",
    "# Copy metrics from previous Unit\n",
    "l = [[\"Numeric Features Only (original)\", 0.686998, 0.609630],\n",
    "    [\"Numeric Features Only (cleaned)\", 0.696141, 0.609630],\n",
    "    [\"Numeric and categorical\", complete_score, complete_loss]]\n",
    "\n",
    "pd.DataFrame(l, columns=[\"Dataset\", \"Score\", \"Loss\"])"
   ]
  },
  {
   "source": [
    "-----\n",
    "\n",
    "## Summary\n",
    "\n",
    "-----"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}